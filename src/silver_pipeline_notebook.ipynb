{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silver Pipeline - Databricks Notebook\n",
    "\n",
    "This notebook implements the Silver layer pipeline for the Medallion architecture (Bronze → Silver → Gold).\n",
    "The pipeline processes data through three sequential stages:\n",
    "\n",
    "- **Silver_A**: Schema selection based on configurable business rules\n",
    "- **Silver_B**: Data transformations with configurable business logic  \n",
    "- **Silver_C**: Deduplication and filtering (placeholder for future enhancements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import DataFrame, functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from typing import Dict, List, Any\n",
    "import logging\n",
    "\n",
    "# Import pipeline modules\n",
    "from utils.config_loader import config_loader\n",
    "import silver_pipeline_stages as stages\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load configuration\n",
    "config = config_loader.load_config()\n",
    "source_combinations = config_loader.get_source_combinations()\n",
    "\n",
    "print(f\"Configuration loaded successfully\")\n",
    "print(f\"Processing {len(source_combinations)} source combinations:\")\n",
    "for source, lob, domain in source_combinations:\n",
    "    print(f\"  - {source}/{lob}/{domain}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the year_month parameter for Bronze table lookup\n",
    "# In production, this would be parameterized or derived from the execution context\n",
    "year_month = \"202407\"  # Modify this as needed\n",
    "\n",
    "print(f\"Using year_month: {year_month}\")\n",
    "print(f\"Bronze schema: {config.bronze_schema}\")\n",
    "print(f\"Silver schema: {config.silver_schema}\")\n",
    "print(f\"Schema rules table: {config.schema_rules_table}\")\n",
    "print(f\"Transform rules table: {config.transform_rules_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver_A Stage - Schema Selection\n",
    "\n",
    "This stage reads Bronze tables and applies schema selection rules to determine which fields to include in Silver_A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_silver_a(source: str, lob: str, domain: str, year_month: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Process Silver_A stage for a given source/lob/domain combination\n",
    "    \n",
    "    Args:\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain (pharmacy, medical, member)\n",
    "        year_month: Year-month string (YYYYMM)\n",
    "        \n",
    "    Returns:\n",
    "        Processed Silver_A DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"Processing Silver_A for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    # Construct Bronze table name\n",
    "    bronze_table = config_loader.get_bronze_table_name(source, lob, domain, year_month)\n",
    "    print(f\"  Bronze table: {bronze_table}\")\n",
    "    \n",
    "    # Check if Bronze table exists\n",
    "    if not stages.validate_bronze_table_exists(bronze_table):\n",
    "        print(f\"  WARNING: Bronze table {bronze_table} does not exist\")\n",
    "        # Return empty DataFrame with placeholder schema\n",
    "        empty_schema = StructType([StructField(\"placeholder\", StringType(), True)])\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    \n",
    "    # Read Bronze table\n",
    "    bronze_df = spark.table(bronze_table)\n",
    "    print(f\"  Bronze table row count: {bronze_df.count()}\")\n",
    "    \n",
    "    # Get schema rules\n",
    "    schema_rules = stages.get_schema_rules(config, source, lob, domain)\n",
    "    print(f\"  Found {len(schema_rules)} schema rules\")\n",
    "    \n",
    "    if schema_rules:\n",
    "        for rule in schema_rules:\n",
    "            print(f\"    - {rule['field_name']} ({rule['data_type']}) [Required: {rule['is_required']}]\")\n",
    "    \n",
    "    # Apply schema selection\n",
    "    silver_a_df = stages.apply_schema_selection(bronze_df, schema_rules)\n",
    "    print(f\"  Silver_A table columns: {silver_a_df.columns}\")\n",
    "    print(f\"  Silver_A table row count: {silver_a_df.count()}\")\n",
    "    \n",
    "    return silver_a_df\n",
    "\n",
    "# Process Silver_A for all source combinations\n",
    "silver_a_tables = {}\n",
    "\n",
    "for source, lob, domain in source_combinations:\n",
    "    table_key = f\"{source}_{lob}_{domain}_silver_a\"\n",
    "    silver_a_df = process_silver_a(source, lob, domain, year_month)\n",
    "    silver_a_tables[table_key] = silver_a_df\n",
    "    \n",
    "    # Create or replace the Silver_A table\n",
    "    silver_a_table_name = f\"{config.silver_schema}.{table_key}\"\n",
    "    silver_a_df.write.mode(\"overwrite\").saveAsTable(silver_a_table_name)\n",
    "    print(f\"  Saved Silver_A table: {silver_a_table_name}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver_B Stage - Business Transformations\n",
    "\n",
    "This stage reads Silver_A tables and applies business transformation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_silver_b(source: str, lob: str, domain: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Process Silver_B stage for a given source/lob/domain combination\n",
    "    \n",
    "    Args:\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain (pharmacy, medical, member)\n",
    "        \n",
    "    Returns:\n",
    "        Processed Silver_B DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"Processing Silver_B for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    # Read Silver_A table\n",
    "    silver_a_table_key = f\"{source}_{lob}_{domain}_silver_a\"\n",
    "    \n",
    "    if silver_a_table_key not in silver_a_tables:\n",
    "        print(f\"  ERROR: Silver_A table not found for {source}/{lob}/{domain}\")\n",
    "        empty_schema = StructType([StructField(\"placeholder\", StringType(), True)])\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    \n",
    "    silver_a_df = silver_a_tables[silver_a_table_key]\n",
    "    print(f\"  Silver_A row count: {silver_a_df.count()}\")\n",
    "    \n",
    "    # Get transformation rules\n",
    "    transform_rules = stages.get_transform_rules(config, source, lob, domain)\n",
    "    print(f\"  Found {len(transform_rules)} transformation rules\")\n",
    "    \n",
    "    if transform_rules:\n",
    "        for rule in transform_rules:\n",
    "            print(f\"    - {rule['field_name']}: {rule['transform']} (Priority: {rule['priority']})\")\n",
    "    \n",
    "    # Apply transformations\n",
    "    silver_b_df = stages.apply_transformations(silver_a_df, transform_rules)\n",
    "    print(f\"  Silver_B table columns: {silver_b_df.columns}\")\n",
    "    print(f\"  Silver_B table row count: {silver_b_df.count()}\")\n",
    "    \n",
    "    return silver_b_df\n",
    "\n",
    "# Process Silver_B for all source combinations\n",
    "silver_b_tables = {}\n",
    "\n",
    "for source, lob, domain in source_combinations:\n",
    "    table_key = f\"{source}_{lob}_{domain}_silver_b\"\n",
    "    silver_b_df = process_silver_b(source, lob, domain)\n",
    "    silver_b_tables[table_key] = silver_b_df\n",
    "    \n",
    "    # Create or replace the Silver_B table\n",
    "    silver_b_table_name = f\"{config.silver_schema}.{table_key}\"\n",
    "    silver_b_df.write.mode(\"overwrite\").saveAsTable(silver_b_table_name)\n",
    "    print(f\"  Saved Silver_B table: {silver_b_table_name}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silver_C Stage - Deduplication and Filtering\n",
    "\n",
    "This stage currently acts as a pass-through but is a placeholder for future deduplication and filtering logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_silver_c(source: str, lob: str, domain: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Process Silver_C stage for a given source/lob/domain combination\n",
    "    Currently a pass-through, placeholder for future enhancements\n",
    "    \n",
    "    Args:\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain (pharmacy, medical, member)\n",
    "        \n",
    "    Returns:\n",
    "        Processed Silver_C DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"Processing Silver_C for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    # Read Silver_B table\n",
    "    silver_b_table_key = f\"{source}_{lob}_{domain}_silver_b\"\n",
    "    \n",
    "    if silver_b_table_key not in silver_b_tables:\n",
    "        print(f\"  ERROR: Silver_B table not found for {source}/{lob}/{domain}\")\n",
    "        empty_schema = StructType([StructField(\"placeholder\", StringType(), True)])\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    \n",
    "    silver_b_df = silver_b_tables[silver_b_table_key]\n",
    "    print(f\"  Silver_B row count: {silver_b_df.count()}\")\n",
    "    \n",
    "    # For now, just pass through the data\n",
    "    # Future enhancements: deduplication, row filtering, data quality scoring\n",
    "    silver_c_df = silver_b_df\n",
    "    \n",
    "    print(f\"  Silver_C table columns: {silver_c_df.columns}\")\n",
    "    print(f\"  Silver_C table row count: {silver_c_df.count()}\")\n",
    "    \n",
    "    return silver_c_df\n",
    "\n",
    "# Process Silver_C for all source combinations\n",
    "silver_c_tables = {}\n",
    "\n",
    "for source, lob, domain in source_combinations:\n",
    "    table_key = f\"{source}_{lob}_{domain}_silver_c\"\n",
    "    silver_c_df = process_silver_c(source, lob, domain)\n",
    "    silver_c_tables[table_key] = silver_c_df\n",
    "    \n",
    "    # Create or replace the Silver_C table\n",
    "    silver_c_table_name = f\"{config.silver_schema}.{table_key}\"\n",
    "    silver_c_df.write.mode(\"overwrite\").saveAsTable(silver_c_table_name)\n",
    "    print(f\"  Saved Silver_C table: {silver_c_table_name}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Validation (Optional)\n",
    "\n",
    "Apply data quality validation to ensure data meets business requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data quality validation if enabled\n",
    "if config.validation_enabled:\n",
    "    print(\"Applying data quality validation...\")\n",
    "    \n",
    "    for source, lob, domain in source_combinations:\n",
    "        print(f\"Validating {source}/{lob}/{domain}\")\n",
    "        \n",
    "        # Validate Silver_A\n",
    "        silver_a_key = f\"{source}_{lob}_{domain}_silver_a\"\n",
    "        if silver_a_key in silver_a_tables:\n",
    "            validated_df = stages.validate_required_fields(\n",
    "                silver_a_tables[silver_a_key], config, source, lob, domain\n",
    "            )\n",
    "            print(f\"  Silver_A validation passed: {validated_df.count()} rows\")\n",
    "        \n",
    "        # Validate Silver_B\n",
    "        silver_b_key = f\"{source}_{lob}_{domain}_silver_b\"\n",
    "        if silver_b_key in silver_b_tables:\n",
    "            validated_df = stages.validate_required_fields(\n",
    "                silver_b_tables[silver_b_key], config, source, lob, domain\n",
    "            )\n",
    "            print(f\"  Silver_B validation passed: {validated_df.count()} rows\")\n",
    "        \n",
    "        # Validate Silver_C\n",
    "        silver_c_key = f\"{source}_{lob}_{domain}_silver_c\"\n",
    "        if silver_c_key in silver_c_tables:\n",
    "            validated_df = stages.validate_required_fields(\n",
    "                silver_c_tables[silver_c_key], config, source, lob, domain\n",
    "            )\n",
    "            print(f\"  Silver_C validation passed: {validated_df.count()} rows\")\n",
    "else:\n",
    "    print(\"Data quality validation is disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Summary\n",
    "\n",
    "Display summary of processed tables and their record counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SILVER PIPELINE EXECUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Processed {len(source_combinations)} source combinations\")\n",
    "print(f\"Year-month parameter: {year_month}\")\n",
    "print(f\"Target schema: {config.silver_schema}\")\n",
    "\n",
    "print(\"\\nTable Summary:\")\n",
    "for source, lob, domain in source_combinations:\n",
    "    print(f\"\\n{source}/{lob}/{domain}:\")\n",
    "    \n",
    "    # Silver_A\n",
    "    silver_a_key = f\"{source}_{lob}_{domain}_silver_a\"\n",
    "    if silver_a_key in silver_a_tables:\n",
    "        count = silver_a_tables[silver_a_key].count()\n",
    "        print(f\"  Silver_A: {count} rows\")\n",
    "    else:\n",
    "        print(f\"  Silver_A: Not processed\")\n",
    "    \n",
    "    # Silver_B\n",
    "    silver_b_key = f\"{source}_{lob}_{domain}_silver_b\"\n",
    "    if silver_b_key in silver_b_tables:\n",
    "        count = silver_b_tables[silver_b_key].count()\n",
    "        print(f\"  Silver_B: {count} rows\")\n",
    "    else:\n",
    "        print(f\"  Silver_B: Not processed\")\n",
    "    \n",
    "    # Silver_C\n",
    "    silver_c_key = f\"{source}_{lob}_{domain}_silver_c\"\n",
    "    if silver_c_key in silver_c_tables:\n",
    "        count = silver_c_tables[silver_c_key].count()\n",
    "        print(f\"  Silver_C: {count} rows\")\n",
    "    else:\n",
    "        print(f\"  Silver_C: Not processed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE EXECUTION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Data Exploration\n",
    "\n",
    "Explore the processed Silver tables to verify results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Display sample data from processed tables\n",
    "# Uncomment and modify as needed for exploration\n",
    "\n",
    "# for source, lob, domain in source_combinations:\n",
    "#     print(f\"\\nSample data for {source}/{lob}/{domain}:\")\n",
    "#     \n",
    "#     # Show Silver_C sample (final stage)\n",
    "#     silver_c_key = f\"{source}_{lob}_{domain}_silver_c\"\n",
    "#     if silver_c_key in silver_c_tables:\n",
    "#         silver_c_tables[silver_c_key].show(5, truncate=False)\n",
    "#     else:\n",
    "#         print(f\"  No data available for {silver_c_key}\")\n",
    "        \n",
    "print(\"Data exploration cell ready - uncomment code above to explore tables\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}