{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silver B - Delta Live Tables\n",
    "\n",
    "This notebook implements the Silver B stage using Delta Live Tables (DLT).\n",
    "Silver B performs business transformations on Silver A tables based on configurable business rules.\n",
    "\n",
    "## Key Features:\n",
    "- Ingests Silver A delta tables\n",
    "- Applies transformation rules from business_rules.transform_definitions\n",
    "- Creates materialized Silver B tables for each source/lob/domain combination\n",
    "- Uses DLT decorators for automatic table creation and dependency management\n",
    "- Supports priority-based transformation ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import dlt\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from typing import Dict, List, Any\n",
    "import logging\n",
    "\n",
    "# Import pipeline modules\n",
    "from utils.config_loader import config_loader\n",
    "import silver_pipeline_stages as stages\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load configuration\n",
    "config = config_loader.load_config()\n",
    "source_combinations = config_loader.get_source_combinations()\n",
    "\n",
    "# Get active Spark session\n",
    "spark = SparkSession.getActiveSession()\n",
    "\n",
    "print(f\"Silver B DLT Pipeline - Configuration loaded\")\n",
    "print(f\"Processing {len(source_combinations)} source combinations\")\n",
    "print(f\"Silver schema: {config.silver_schema}\")\n",
    "print(f\"Transform rules table: {config.transform_rules_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Silver B Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_silver_b_table(source: str, lob: str, domain: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Create Silver B table for a specific source/lob/domain combination\n",
    "    \n",
    "    Args:\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain (pharmacy, medical, member)\n",
    "        \n",
    "    Returns:\n",
    "        Processed Silver B DataFrame\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creating Silver B table for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    # Read Silver A table using DLT\n",
    "    silver_a_table_name = f\"{source}_{lob}_{domain}_silver_a\"\n",
    "    \n",
    "    try:\n",
    "        # Use DLT read to get the Silver A table\n",
    "        silver_a_df = dlt.read(silver_a_table_name)\n",
    "        logger.info(f\"Successfully read Silver A table: {silver_a_table_name}\")\n",
    "        \n",
    "        # Get row count for logging\n",
    "        row_count = silver_a_df.count()\n",
    "        logger.info(f\"Silver A table contains {row_count} rows\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read Silver A table {silver_a_table_name}: {e}\")\n",
    "        # Return empty DataFrame if Silver A doesn't exist\n",
    "        empty_schema = StructType([StructField(\"placeholder\", StringType(), True)])\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    \n",
    "    # Get transformation rules from business rules table\n",
    "    transform_rules = stages.get_transform_rules(config, source, lob, domain)\n",
    "    logger.info(f\"Found {len(transform_rules)} transformation rules for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    if transform_rules:\n",
    "        for rule in transform_rules:\n",
    "            logger.debug(f\"Transform rule: {rule['field_name']} -> {rule['transform']} (Priority: {rule['priority']})\")\n",
    "    \n",
    "    # Apply transformations\n",
    "    try:\n",
    "        silver_b_df = stages.apply_transformations(silver_a_df, transform_rules)\n",
    "        logger.info(f\"Silver B processing complete - {silver_b_df.count()} rows, columns: {silver_b_df.columns}\")\n",
    "        return silver_b_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to apply transformations for {source}/{lob}/{domain}: {e}\")\n",
    "        # Return original DataFrame if transformations fail\n",
    "        return silver_a_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Expectations for Silver B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_silver_b_quality_checks(df: DataFrame, source: str, lob: str, domain: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Apply data quality checks specific to Silver B stage\n",
    "    \n",
    "    Args:\n",
    "        df: Silver B DataFrame\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with quality checks applied\n",
    "    \"\"\"\n",
    "    if not config.validation_enabled:\n",
    "        logger.info(\"Data quality validation is disabled\")\n",
    "        return df\n",
    "    \n",
    "    logger.info(f\"Applying Silver B quality checks for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    # Apply required field validation\n",
    "    validated_df = stages.validate_required_fields(df, config, source, lob, domain)\n",
    "    \n",
    "    # Additional Silver B specific validations can be added here\n",
    "    # For example: data type validations after transformations\n",
    "    \n",
    "    logger.info(f\"Quality checks complete - {validated_df.count()} rows passed validation\")\n",
    "    return validated_df\n",
    "\n",
    "\n",
    "def validate_transformation_success(df: DataFrame, source: str, lob: str, domain: str) -> bool:\n",
    "    \"\"\"\n",
    "    Additional validation to ensure transformations were applied successfully\n",
    "    \n",
    "    Args:\n",
    "        df: Transformed DataFrame\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if transformations were successful\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if DataFrame has data\n",
    "        if df.count() == 0:\n",
    "            logger.warning(f\"No data in Silver B table for {source}/{lob}/{domain}\")\n",
    "            return False\n",
    "        \n",
    "        # Check if DataFrame has expected columns (based on schema rules)\n",
    "        schema_rules = stages.get_schema_rules(config, source, lob, domain)\n",
    "        expected_fields = [rule['field_name'] for rule in schema_rules]\n",
    "        \n",
    "        missing_fields = [field for field in expected_fields if field not in df.columns]\n",
    "        if missing_fields:\n",
    "            logger.warning(f\"Missing expected fields in Silver B for {source}/{lob}/{domain}: {missing_fields}\")\n",
    "            return False\n",
    "        \n",
    "        logger.info(f\"Transformation validation passed for {source}/{lob}/{domain}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Transformation validation failed for {source}/{lob}/{domain}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLT Table Definitions\n",
    "\n",
    "Dynamic generation of DLT tables for each source/lob/domain combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DLT table definitions for each source/lob/domain combination\n",
    "for source, lob, domain in source_combinations:\n",
    "    \n",
    "    # Create a closure to capture the current values of source, lob, domain\n",
    "    def make_silver_b_table(src, lb, dom):\n",
    "        \n",
    "        @dlt.table(\n",
    "            name=f\"{src}_{lb}_{dom}_silver_b\",\n",
    "            comment=f\"Silver B stage for {src}/{lb}/{dom} - Business transformations based on rules\",\n",
    "            table_properties={\n",
    "                \"quality\": \"silver\",\n",
    "                \"layer\": \"silver_b\",\n",
    "                \"source\": src,\n",
    "                \"lob\": lb,\n",
    "                \"domain\": dom\n",
    "            }\n",
    "        )\n",
    "        @dlt.expect_all_or_drop(\"valid_silver_b_data\")\n",
    "        def silver_b_table():\n",
    "            \"\"\"\n",
    "            Create Silver B table with transformations from Silver A\n",
    "            \"\"\"\n",
    "            # Create Silver B DataFrame\n",
    "            silver_b_df = create_silver_b_table(src, lb, dom)\n",
    "            \n",
    "            # Validate transformation success\n",
    "            if not validate_transformation_success(silver_b_df, src, lb, dom):\n",
    "                logger.warning(f\"Transformation validation failed for {src}/{lb}/{dom}\")\n",
    "            \n",
    "            # Apply quality checks\n",
    "            validated_df = apply_silver_b_quality_checks(silver_b_df, src, lb, dom)\n",
    "            \n",
    "            return validated_df\n",
    "        \n",
    "        return silver_b_table\n",
    "    \n",
    "    # Create the table function and add it to the global namespace\n",
    "    table_func = make_silver_b_table(source, lob, domain)\n",
    "    globals()[f\"{source}_{lob}_{domain}_silver_b\"] = table_func\n",
    "    \n",
    "    print(f\"Created DLT table definition: {source}_{lob}_{domain}_silver_b\")\n",
    "\n",
    "print(f\"\\nTotal Silver B tables defined: {len(source_combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced DLT Expectations for Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional DLT expectations that can be applied to Silver B tables\n",
    "# These are optional and can be customized based on business requirements\n",
    "\n",
    "def create_advanced_expectations():\n",
    "    \"\"\"\n",
    "    Create advanced DLT expectations for Silver B tables\n",
    "    These can be applied to specific tables based on business requirements\n",
    "    \"\"\"\n",
    "    \n",
    "    # Example: Expect certain fields to not be null after transformation\n",
    "    @dlt.expect(\"patient_id_not_null\")\n",
    "    def expect_patient_id_not_null(df):\n",
    "        return F.col(\"patient_id\").isNotNull()\n",
    "    \n",
    "    # Example: Expect transformed dates to be in valid format\n",
    "    @dlt.expect(\"valid_date_format\")\n",
    "    def expect_valid_date_format(df):\n",
    "        # This would check if date columns are in expected format after transformation\n",
    "        return F.col(\"service_date\").rlike(r'^\\d{4}-\\d{2}-\\d{2}$')\n",
    "    \n",
    "    # Example: Expect numeric fields to be within reasonable ranges\n",
    "    @dlt.expect(\"valid_amount_range\")\n",
    "    def expect_valid_amount_range(df):\n",
    "        return (F.col(\"amount\") >= 0) & (F.col(\"amount\") <= 999999.99)\n",
    "    \n",
    "    logger.info(\"Advanced DLT expectations defined\")\n",
    "\n",
    "# Uncomment the line below to enable advanced expectations\n",
    "# create_advanced_expectations()\n",
    "\n",
    "print(\"Advanced expectations available but not enabled by default\")\n",
    "print(\"Uncomment create_advanced_expectations() call to enable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Monitoring and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log pipeline configuration for monitoring\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"SILVER B DLT PIPELINE CONFIGURATION\")\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(f\"Pipeline stage: Silver B (Business Transformations)\")\n",
    "logger.info(f\"Silver schema: {config.silver_schema}\")\n",
    "logger.info(f\"Transform rules table: {config.transform_rules_table}\")\n",
    "logger.info(f\"Validation enabled: {config.validation_enabled}\")\n",
    "logger.info(f\"Source combinations: {len(source_combinations)}\")\n",
    "\n",
    "for i, (source, lob, domain) in enumerate(source_combinations, 1):\n",
    "    logger.info(f\"  {i}. {source}/{lob}/{domain}:\")\n",
    "    logger.info(f\"     Input:  {source}_{lob}_{domain}_silver_a\")\n",
    "    logger.info(f\"     Output: {source}_{lob}_{domain}_silver_b\")\n",
    "\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"SILVER B DLT PIPELINE READY\")\n",
    "logger.info(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "To use this notebook in Databricks DLT:\n",
    "\n",
    "1. **Create a new DLT Pipeline** in the Databricks workspace\n",
    "2. **Set the source** to this notebook (`silver_b_dlt.ipynb`)\n",
    "3. **Configure pipeline settings**:\n",
    "   - Target schema: `silver` (or your configured silver schema)\n",
    "   - Pipeline mode: `Triggered` for batch processing\n",
    "   - Cluster configuration: Based on your data volume\n",
    "4. **Ensure dependencies**:\n",
    "   - Silver A tables must exist (either from Silver A DLT pipeline or other source)\n",
    "   - Business rules tables must exist (`business_rules.transform_definitions`)\n",
    "   - Utils modules must be available in the workspace\n",
    "5. **Pipeline Dependencies**:\n",
    "   - This pipeline should run AFTER the Silver A pipeline\n",
    "   - Set up proper scheduling or triggering to ensure Silver A tables are available\n",
    "\n",
    "**Input Tables**: This pipeline reads from:\n",
    "- `{silver_schema}.{source}_{lob}_{domain}_silver_a`\n",
    "\n",
    "**Output Tables**: This pipeline creates:\n",
    "- `{silver_schema}.{source}_{lob}_{domain}_silver_b`\n",
    "\n",
    "**Dependencies**: This pipeline depends on:\n",
    "- Silver A tables: `{silver_schema}.{source}_{lob}_{domain}_silver_a`\n",
    "- Business rules: `business_rules.transform_definitions`\n",
    "\n",
    "**Transformation Logic**:\n",
    "- Transformations are applied in priority order (ascending)\n",
    "- Multiple transformations can be applied to the same field\n",
    "- Failed transformations are logged but don't stop the pipeline\n",
    "- Supports SQL expressions in transformation rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}