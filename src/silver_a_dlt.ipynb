{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silver A - Delta Live Tables\n",
    "\n",
    "This notebook implements the Silver A stage using Delta Live Tables (DLT).\n",
    "Silver A performs schema selection based on configurable business rules from Bronze tables.\n",
    "\n",
    "## Key Features:\n",
    "- Ingests Bronze delta tables\n",
    "- Applies schema selection rules from business_rules.schema_definitions\n",
    "- Creates materialized Silver A tables for each source/lob/domain combination\n",
    "- Uses DLT decorators for automatic table creation and dependency management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import dlt\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from typing import Dict, List, Any\n",
    "import logging\n",
    "\n",
    "# Import pipeline modules\n",
    "from utils.config_loader import config_loader\n",
    "import silver_pipeline_stages as stages\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load configuration\n",
    "config = config_loader.load_config()\n",
    "source_combinations = config_loader.get_source_combinations()\n",
    "\n",
    "# Get active Spark session\n",
    "spark = SparkSession.getActiveSession()\n",
    "\n",
    "print(f\"Silver A DLT Pipeline - Configuration loaded\")\n",
    "print(f\"Processing {len(source_combinations)} source combinations\")\n",
    "print(f\"Bronze schema: {config.bronze_schema}\")\n",
    "print(f\"Silver schema: {config.silver_schema}\")\n",
    "print(f\"Schema rules table: {config.schema_rules_table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters\n",
    "\n",
    "Set pipeline parameters that can be configured when running the DLT pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline parameters - these can be overridden when running the DLT pipeline\n",
    "# Default year_month for Bronze table lookup\n",
    "year_month = spark.conf.get(\"pipeline.year_month\", \"202407\")\n",
    "\n",
    "print(f\"Using year_month parameter: {year_month}\")\n",
    "print(f\"To override, set pipeline.year_month configuration when running DLT pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Silver A Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_silver_a_table(source: str, lob: str, domain: str, year_month: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Create Silver A table for a specific source/lob/domain combination\n",
    "    \n",
    "    Args:\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain (pharmacy, medical, member)\n",
    "        year_month: Year-month string (YYYYMM)\n",
    "        \n",
    "    Returns:\n",
    "        Processed Silver A DataFrame\n",
    "    \"\"\"\n",
    "    logger.info(f\"Creating Silver A table for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    # Construct Bronze table name\n",
    "    bronze_table = config_loader.get_bronze_table_name(source, lob, domain, year_month)\n",
    "    logger.info(f\"Reading from Bronze table: {bronze_table}\")\n",
    "    \n",
    "    # Check if Bronze table exists\n",
    "    if not stages.validate_bronze_table_exists(bronze_table):\n",
    "        logger.warning(f\"Bronze table {bronze_table} does not exist, returning empty DataFrame\")\n",
    "        # Return empty DataFrame with placeholder schema\n",
    "        empty_schema = StructType([StructField(\"placeholder\", StringType(), True)])\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    \n",
    "    # Read Bronze table\n",
    "    try:\n",
    "        bronze_df = spark.table(bronze_table)\n",
    "        logger.info(f\"Successfully read Bronze table with {bronze_df.count()} rows\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read Bronze table {bronze_table}: {e}\")\n",
    "        empty_schema = StructType([StructField(\"placeholder\", StringType(), True)])\n",
    "        return spark.createDataFrame([], empty_schema)\n",
    "    \n",
    "    # Get schema rules from business rules table\n",
    "    schema_rules = stages.get_schema_rules(config, source, lob, domain)\n",
    "    logger.info(f\"Found {len(schema_rules)} schema rules for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    if schema_rules:\n",
    "        for rule in schema_rules:\n",
    "            logger.debug(f\"Schema rule: {rule['field_name']} ({rule['data_type']}) [Required: {rule['is_required']}]\")\n",
    "    \n",
    "    # Apply schema selection\n",
    "    try:\n",
    "        silver_a_df = stages.apply_schema_selection(bronze_df, schema_rules)\n",
    "        logger.info(f\"Silver A processing complete - {silver_a_df.count()} rows, columns: {silver_a_df.columns}\")\n",
    "        return silver_a_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to apply schema selection for {source}/{lob}/{domain}: {e}\")\n",
    "        # Return original DataFrame if schema selection fails\n",
    "        return bronze_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Expectations for Silver A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_silver_a_quality_checks(df: DataFrame, source: str, lob: str, domain: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Apply data quality checks specific to Silver A stage\n",
    "    \n",
    "    Args:\n",
    "        df: Silver A DataFrame\n",
    "        source: Source identifier\n",
    "        lob: Line of business\n",
    "        domain: Domain\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with quality checks applied\n",
    "    \"\"\"\n",
    "    if not config.validation_enabled:\n",
    "        logger.info(\"Data quality validation is disabled\")\n",
    "        return df\n",
    "    \n",
    "    logger.info(f\"Applying Silver A quality checks for {source}/{lob}/{domain}\")\n",
    "    \n",
    "    # Apply required field validation\n",
    "    validated_df = stages.validate_required_fields(df, config, source, lob, domain)\n",
    "    \n",
    "    logger.info(f\"Quality checks complete - {validated_df.count()} rows passed validation\")\n",
    "    return validated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLT Table Definitions\n",
    "\n",
    "Dynamic generation of DLT tables for each source/lob/domain combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DLT table definitions for each source/lob/domain combination\n",
    "for source, lob, domain in source_combinations:\n",
    "    \n",
    "    # Create a closure to capture the current values of source, lob, domain\n",
    "    def make_silver_a_table(src, lb, dom):\n",
    "        \n",
    "        @dlt.table(\n",
    "            name=f\"{src}_{lb}_{dom}_silver_a\",\n",
    "            comment=f\"Silver A stage for {src}/{lb}/{dom} - Schema selection based on business rules\",\n",
    "            table_properties={\n",
    "                \"quality\": \"silver\",\n",
    "                \"layer\": \"silver_a\",\n",
    "                \"source\": src,\n",
    "                \"lob\": lb,\n",
    "                \"domain\": dom\n",
    "            }\n",
    "        )\n",
    "        @dlt.expect_all_or_drop(\"valid_silver_a_data\")\n",
    "        def silver_a_table():\n",
    "            \"\"\"\n",
    "            Create Silver A table with schema selection from Bronze\n",
    "            \"\"\"\n",
    "            # Create Silver A DataFrame\n",
    "            silver_a_df = create_silver_a_table(src, lb, dom, year_month)\n",
    "            \n",
    "            # Apply quality checks\n",
    "            validated_df = apply_silver_a_quality_checks(silver_a_df, src, lb, dom)\n",
    "            \n",
    "            return validated_df\n",
    "        \n",
    "        return silver_a_table\n",
    "    \n",
    "    # Create the table function and add it to the global namespace\n",
    "    table_func = make_silver_a_table(source, lob, domain)\n",
    "    globals()[f\"{source}_{lob}_{domain}_silver_a\"] = table_func\n",
    "    \n",
    "    print(f\"Created DLT table definition: {source}_{lob}_{domain}_silver_a\")\n",
    "\n",
    "print(f\"\\nTotal Silver A tables defined: {len(source_combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Monitoring and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log pipeline configuration for monitoring\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"SILVER A DLT PIPELINE CONFIGURATION\")\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(f\"Pipeline stage: Silver A (Schema Selection)\")\n",
    "logger.info(f\"Year-month parameter: {year_month}\")\n",
    "logger.info(f\"Bronze schema: {config.bronze_schema}\")\n",
    "logger.info(f\"Silver schema: {config.silver_schema}\")\n",
    "logger.info(f\"Schema rules table: {config.schema_rules_table}\")\n",
    "logger.info(f\"Validation enabled: {config.validation_enabled}\")\n",
    "logger.info(f\"Source combinations: {len(source_combinations)}\")\n",
    "\n",
    "for i, (source, lob, domain) in enumerate(source_combinations, 1):\n",
    "    logger.info(f\"  {i}. {source}/{lob}/{domain} -> {source}_{lob}_{domain}_silver_a\")\n",
    "\n",
    "logger.info(\"=\"*60)\n",
    "logger.info(\"SILVER A DLT PIPELINE READY\")\n",
    "logger.info(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Instructions\n",
    "\n",
    "To use this notebook in Databricks DLT:\n",
    "\n",
    "1. **Create a new DLT Pipeline** in the Databricks workspace\n",
    "2. **Set the source** to this notebook (`silver_a_dlt.ipynb`)\n",
    "3. **Configure pipeline settings**:\n",
    "   - Target schema: `silver` (or your configured silver schema)\n",
    "   - Pipeline mode: `Triggered` for batch processing\n",
    "   - Cluster configuration: Based on your data volume\n",
    "4. **Set pipeline parameters** (optional):\n",
    "   - `pipeline.year_month`: Override the default year-month for Bronze table lookup\n",
    "5. **Ensure dependencies**:\n",
    "   - Business rules tables must exist (`business_rules.schema_definitions`)\n",
    "   - Bronze tables must exist with the expected naming pattern\n",
    "   - Utils modules must be available in the workspace\n",
    "\n",
    "**Output Tables**: This pipeline will create Silver A tables with names like:\n",
    "- `{silver_schema}.{source}_{lob}_{domain}_silver_a`\n",
    "\n",
    "**Dependencies**: This pipeline depends on:\n",
    "- Bronze tables: `{bronze_schema}.{source}_{lob}_{domain}_{year_month}`\n",
    "- Business rules: `business_rules.schema_definitions`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}